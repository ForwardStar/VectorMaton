# Substring-ANN
An elegant vector database that supports hybrid queries of ANNs whose associated strings contain a queried substring. Each data in the vector database consists of a string and a vector. Each query contains a string, a vector, and an integer k to return approximated k-nearest neighbors. The query results will contain data that involves the queried string as a substring, and its vector is an approximated k-nearest neighbor of the queried vector under the substring constraint. In this project, we use Euclidean distance as the measure of closeness, but it can be simply extended to support other metrics.

Example scenario:
- In bioinformatics, each protein can be represented by (ùë†,ùë£), where ùë† is its amino acid sequence (e.g., Leu-Ser-Met) and ùë£ is its 2D or 3D structural embedding (e.g., AlphaFold embeddings);

- Query: searching the k-most similar protein structures containing a specific motif (i.e., a substring of amino acid sequence).

Example query:
- There are 4 (ùë†,ùë£) pairs in the vector database: ("ATP synthase subunit beta", [0, 1, 2]), ("ATP-dependent helicase", [3, 4, 5]), ("DNA polymerase III", [6, 7, 8]), ("Lactate dehydrogenase", [9, 10, 11])
- Query 1: k=2, v=[5, 6, 7], s=""
- Result 1: ("ATP-dependent helicase", [3, 4, 5]), ("DNA polymerase III", [6, 7, 8])
- To be more specific, this returns the 2-NNs of vector v with an empty substring constraint, which is equalalent to the classic ANN search;
- Query 2: k=2, v=[5, 6, 7], s="ATP"
- Result 2: ("ATP synthase subunit beta", [0, 1, 2]), ("ATP-dependent helicase", [3, 4, 5])
- This gives a substring constraint "ATP"; therefore, only data containing "ATP" as a substring will be considered.

# Compile and run
Parts of the project depends on ``openssl``. Install on Ubuntu:
```sh
sudo apt-get install libssl-dev
```

We developed and tested this vector database under ``GCC 10.5.0`` with ``O3`` optimization. To compile the codes, simply run:
```sh
mkdir build && cd build
cmake ..
make
```

This will generate executable files ``nsw_test``, ``sa_test``, ``db_test`` and ``main``. In particular, ``db_test`` corresponds to ``source/test_vector_db.cpp``, which provides a demo on how to use the vector database. ``sa_test`` and ``nsw_test`` are testing programs for the algorithms used in the database.

The ``main`` is our experimental program. Run with:
```sh
./main <string_data_file> <vector_data_file> <string_query_file> <vector_query_file> <k_query_file> <output_file> <Exact|Baseline|VectorDB>
```

# Computing recall
To compute the average recall, run:
```sh
python3 compute_recall.py <exact_output_file> <actual_output_file>
```

# Datasets
Since there are no existing vector datasets associated with strings, we include synthetic datasets for experiments, where the strings are original natural language texts and the vectors are their embeddings generated by pre-trained language models. The datasets include:
- [CodeSearchNet](https://huggingface.co/datasets/irds/codesearchnet): a dataset of code snippets and their embeddings; to be specific, each data consists of a function name as its string and a code embedding vector (generated by CodeBERT) as its vector;

We provide a Python script ``generate_datasets.py`` to download and generate aforementioned datasets. The generated datasets are stored in the ``datasets/`` folder. Each dataset contains a file ``vectors.txt`` and a file ``strings.txt``, where the i-th line of ``vectors.txt`` and the i-th line of ``strings.txt`` correspond to the vector and string of the i-th data, respectively. To execute the script, please first install the required ``datasets``, ``numpy``, ``transformers`` and ``torch`` packages via:
```sh
pip install datasets==3.6.0 numpy==1.26.4 transformers==4.56.0 torch==2.8.0
```

Note that: at the time of our development, some datasets are not compatible with ``datasets`` library version later than 3.6.0, so please make sure to install the exact version above.

Then run:
```sh
python3 generate_datasets.py
```

Note that the script may take hours to finish, as it needs to download the dataset and compute the embeddings. The script does not support checkpointing for single dataset, so if it is interrupted, you need to delete that dataset folder and restart it. The script will skip the dataset generation if the dataset already exists.

# APIs
Refer to ``source/test_vector_db.cpp`` as a demo example.

Include the header file:
```cpp
#include "substring-ANN/source/vector_db.h"
```

Initiate a vector DB instance:
```cpp
VectorDB db;
```

Insert a vector with its associated string (possibly empty, which is then in line with the basic vector database with no substring query support):
```cpp
// Interface
// int insert(const std::vector<float>& vec, const std::string &s);

// Example
int id = db.insert({1.0, 2.0, 3.0}, "banana"); // automatically generate a unique `id` for the data
```

Remove data:
```cpp
// Interface
// void remove(int id);

// Example
db.remove(0);
```

Query the kNNs of a vector with a substring constraint:
```cpp
// Interface
// std::vector<int> query(const std::vector<float>& vec, const std::string &s, int k);

// Example
std::vector<int> res = db.query({9.0, 10.0, 11.0}, "ana", 2) // `res` contains the data `id`s of the queried result
```